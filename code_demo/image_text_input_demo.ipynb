{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16abb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPT-4o Image + Text Demo ===\n",
      "Demonstrating image reasoning with text prompt\n",
      "\n",
      "Input Modalities:\n",
      "  Image: algorithm_10.png\n",
      "  Text:  'Can you explain line 6 of the algorithm?'\n",
      "\n",
      "Processing...\n",
      "\n",
      "Response generated in 13640 ms\n",
      "\n",
      "Text Response:\n",
      "\n",
      "Certainly! Line 6 of the algorithm employs the multi-head attention mechanism. Here's a breakdown of what each part is doing:\n",
      "\n",
      "- `Ĥ` is the result of applying layer normalization to `X`. The inputs to this normalization are the token sequences `X` and the parameters `γ¹_ℓ` and `β¹_ℓ`, which are specific to layer `ℓ`.\n",
      "\n",
      "- `MHA` stands for Multi-Head Attention. This function performs the attention mechanism, which allows the model to focus on different parts of the input sequence when producing each element of the output sequence.\n",
      "\n",
      "- The inputs to `MHA` are:\n",
      "  - `Ĥ`: The normalized input.\n",
      "  - `W_ℓ`: Parameters for the multi-head attention, which include weights for the attention heads.\n",
      "  - `Mask[i,j] = [[i ≤ j]]`: A mask that ensures attention only attends to positions up to `i` (causal attention), preventing information from future tokens from being accessed. This is crucial for maintaining the autoregressive property of the model.\n",
      "\n",
      "- The output of this attention mechanism is added back to `X`. This is a form of residual connection, helping to stabilize training and preserve original input information while allowing the model to learn complex interactions.\n",
      "\n",
      "**Overall,** line 6 applies multi-head attention with causal masking, leveraging positions `i` or earlier, facilitating effective learning by directing the model's focus adaptively across the input sequence.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import base64\n",
    "import time\n",
    "\n",
    "# Setup\n",
    "client = openai.OpenAI(api_key=\"\") # removed actual API key used here since will be uploading to github\n",
    "\n",
    "print(\"=== GPT-4o Image + Text Demo ===\")\n",
    "print(\"Demonstrating image reasoning with text prompt\\n\")\n",
    "\n",
    "# Read the algorithm image\n",
    "with open(\"algorithm_10.png\", \"rb\") as img_file:\n",
    "    image_base64 = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "print(\"Input Modalities:\")\n",
    "print(\"  Image: algorithm_10.png\")\n",
    "print(\"  Text:  'Can you explain line 6 of the algorithm?'\")\n",
    "print(\"\\nProcessing...\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{image_base64}\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Can you explain line 6 of the algorithm?\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"\\nResponse generated in {(end - start) * 1000:.0f} ms\")\n",
    "print(\"\\nText Response:\\n\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
